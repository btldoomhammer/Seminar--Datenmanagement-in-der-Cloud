\chapter{Zusammenfassung und Ausblick}
\label{sec:Zusammenfassung-Ausblick}

\section{Zusammenfassung}
\label{sec:Zusammenfassung}

Durch den Paradigmenwechsel von immer schnelleren Prozessoren hin zu Multicore-Prozessoren greifen die bisherigen Optimierungen nur noch begrenzt. Daher müssen neue Ideen und Algorithmen umgesetzt werden, damit Datenbank-Systeme mit den steigenden Anforderungen schritthalten können. Dies erfordert einen neuen Umgang mit Zugriffen auf den Hauptspeicher und den Cache. Aber auch die Planung der Prozessor-Pipeline und der Prozessverteilung wird immer wichtiger.

Um diese Optimierung durchzuführen können einerseits einzelne Teilbereiche und Datenbankoperationen einzeln optimiert werden, wie es beim AA-Sort und AA-Hash Join der Fall ist. Diese beiden Algorithmen versuchen für eine konkrete Aufgabenstellung Zugriffe auf den Cache so zu optimieren, dass paralleler Zugriff optimal möglich ist, ohne zu viele Cache-Miss und Pipeline-Abbrüche zu erzeugen. Dadurch können sie ihren Aufgabenbereich deutlich beschleunigen.

Andererseits kann die Optimierung auch globaler betrachtet werden. Beim Minimizing Cache Conficts Ansatz geht es darum, den Cache Datenbank-übergreifend zu verwalten. Datenbankoperationen werden anhand ihres Cache Bedarfs eingeteilt um sie anhand dieses Kriteriums optimal zu verteilen und zu bearbeiten. Dies geschieht um einen Zugriffsplan. Beim Auto-Tuning geht es ebenfalls um die Optimierung des Zugriffsplans. Hier wird jedoch auf ein evolutionäres System gesetzt, dass sich selbst optimieren kann. Wiederkehrende Anfragen werden systematisch mit unterschiedlichen Pattern und Cachezuweisungen aufgerufen und die so gewonnenen Daten werden für die automatische Optimierung herangezogen. Dabei werden auch Teile des Zugriffsplans auf unterschiedliche Prozesse verteilt, wodurch auch eine ideale Prozessaufteilung entsteht.

Beide Herangehensweise können signifikante Leistungssteigerungen erzeugen, so das davon auszugehen ist, dass in Zukunft Datenbanksysteme auf einige, oder - wenn möglich - mehrere dieser Optimierungen einsetzen werden.


\section{Andere Ansätze}
\label{sec:AndereAnsatze}
Die in dieser Ausarbeitung im Detail vorgestellten Algorithmen sind nur ein Teil der Möglichkeiten, mehrere Prozesse für Datenbankabfrage-Optimierung zu nutzen. Um einen kleinen Blick auf diese anderen Ansätze zu werfen, werden im folgenden einige der Interessanteren betrachtet. Es gibt jedoch zusätzlich noch weitere Ansätze und Algorithmen, die hier nicht mehr erwähnt werden. Die meisten Dieser ähneln jedoch denen im Detail vorgestellten Algorithmen indem sich versuchen, die Zugriffe auf den Speicher zu optimieren und Cache-Misses und Pipeline-Abbrüche zu reduzieren.

\subsection{Netzwerkprozessor}
\label{sec:Netzwerkprozessor}

Ein Ansatz mehrere Prozesse optimaler zu unterstützen ist es, spezielle Prozessoren zu verwenden, die besser geeignet sind mit einer großen Anzahl von Prozessen umzugehen. \cite{GOLD} Netzwerkprozessoren sind spezielle Prozessoren die sich durch eine auf Prozesse spezialisierte Architektur auszeichnen. Pro Prozessorkern – Microengine genannt – können bis zu 8 Prozesse parallel arbeiten und durch spezielle Register und Cache kann ein Kontextwechsel ohne großen Overhead in einem einzelnen Prozessorzyklus durchgeführt werden.

Durch die spezielle Art der Hardware wird jedoch der Programmieraufwand größer. Viele automatisierte Vorgänge müssen durch das Programm selber durchgeführt werden. Ein Prozesswechsel muss explizit angegeben werden und der nächste Prozess wird nach dem Round-Robin Verfahren ausgewählt. Der Prefetcher muss ebenfalls vom Programmierer selber festgelegt werden. Dadurch kann kontrolliert werden, dass kritische Daten auch wirklich immer im Speicher liegen und nicht erst nach einem Cache-Miss neu geladen werden müssen. Andere Daten können explizit im RAM belassen werden.

Ein Sequenzieller Scan einer Tabelle einer Datenbank kann beispielsweise so aufgeteilt werden, dass eine Page pro Microengine durchsucht wird. Die 8 Prozesse der Microengine bearbeiten jeweils einen Eintrag. Dafür wird die Page explizit in den Cache der Microengine geladen.

Da Netzwerkprozessoren nur über wenig zusammenhängendem Cache verfügt, besteht gerade beim HashJoin die Gefahr, dass die Buckets zu groß werden. Da ihre Größe nicht effektiv vorhergesehen werden kann muss die Hashtabelle sicherheitshalber im RAM belassen werden. Es entsteht ein größerer Overhead beim Zugriff auf die Tabellen. Aber durch die parallele Bearbeitung der Pages gibt es dennoch einen zeitlichen Gewinn.

Die Verwendung eines Netzwerkprozessors ist aufgrund des umfangreicheren Programmieraufwandes nicht einfach, kann aber mit anderen Optimierungen und Algorithmen zusammen verwendet werden. Vermutlich lassen sich die in dieser Ausarbeitung vorgestellten Algorithmen und Ansätze auch auf einen Netzwerkprozessor übertragen, in manchen Fällen vielleicht sogar effektiver als auf einem herkömmlichen Prozessor.


\subsection{CUDA}
\label{sec:CUDA}

Im Vergleich zu CPUs besitzen die meisten modernen GPUs (Grafikprozessoren) eine ca 10x höhere Rechenleistung und 10x größere Speicherbandbreite. Zusätzlich sind sie bereits für Multiprozess-Tätigkeiten optimiert, bieten schnelle Kommunikation zwischen Prozessen und erlauben zufälligen Zugriff auf Speicheradressen. Dies wird durch on-chip Speicher erreicht, der zusätzlich zum schnellen Grafikspeicher verwendet wird. All dies sind Eigenschaften, die bei einer Multiprozess-Datenbank erwünscht sind. Problem ist hier jedoch, dass die Kommunikation zwischen CPU und GPU über den BUS abläuft mit begrenzte Bandbreite abläuft. Effektiver RAM- und Festplattenzugriff ist daher unmöglich. Das reduziert den Nutzen auf Operationen mit einer festen Datenmenge. Die Daten müssen einmalig auf die GPU übertragen werden und können dort gehalten werden.

Über die Programmiersprache CUDA kann die GPU programmiert werden und das nicht nur für grafische Anwendungen. So kann die GPU in einen Coprozessor verwandelt werden, der Relationsanfragen bearbeiten kann und Arbeitskraft der CPU für andere Speicherzugriffs-lastige Aufgaben freimacht. \cite{HE} Optimierte Algorithmen sind jedoch erforderlich, um den Nachteil der Bustransferrate auszugleichen. Pro GPU-Prozessorkern laufen ganze Prozessgruppen. SIMD Unterstützung und Architektur sind einem Netzwerkprozessor nicht unähnlich. Das in [Quelle] erstellte System setzt einen Abschätzungsmechanismus ein, um Aufgaben, die Idealerweise auf der GPU verarbeitet werden könne, an diese weiterzugeben. Hierbei wird die Bus-Transferrate mit berücksichtigt um einen Leistungsgewinn zu erzielen. Durch die Bus-Limitierung ist es erforderlich, die kommunizierten Daten genau zu planen. Sämtliche Anweisungen und Daten, alle Tupel und Indexe werden an die GPU übertragen. Bei Abschluss der Arbeit wird ausschließlich das Endprodukt zurückgeliefert. Es lassen sich ausschließlich read-only Datenbankoperationen durchführen. Änderungen können durch den GPU Coprozessor nicht in akzeptabler Zeit realisiert werden.

Somit ist der Einsatz der GPU eher als Unterstützung zu sehen. Sie erlaubt es, der CPU Arbeit abzunehmen und CUDA kann somit parallel zu den anderen hier vorgestellten Algorithmen und Ansätzen zur Leistungssteigerung einer Datenbankanwendung eingesetzt werden.


\subsection{Mehrere Datenbank-Engines}
\label{sec:DBEngines}

Ein Ansatz der Optimierung von Datenbanken an ein Multicore-System ist es, die Hardware als ein verteiltes System zu behandeln. In diesem Sinne wird nicht die Behandlung einer Datenbankanfrage auf die Prozesse verteilt, sondern die Datenbank selber. Somit gibt es mehrere Datenbankengines, die auf dem selben Rechner laufen. Das bedeutet, dass nur noch eine Middleware-Schicht entwickelt werden muss, die die Anfragen auf die verteilte Datenbank-Engines vermittelt.

\textit{Multimed} \cite{SALOMIE} ist das Konzept einer derartigen Datenbank-Engine. Es setzt dabei auf eine Master-Datenbank und mehrere Satelliten-Datenbanken. Vorteilhaft ist eine leichte Skalierbarkeit, da sich mit steigenden Prozessorkern-Anzahl einfach die Anzahl der Satelliten erhöht werden kann. Das bereits existierende Know-How verteilter Datenbanken kann eingesetzt werden. Nach außen hin tritt \textit{Multimed} wie eine einzelne Datenbankengien auf. Updates werden auf der Master-Datenbank durchgeführt und asynchron an die Satelliten weitergegeben. Datenbankanfragen die kein Update erfordern, werden hingegen von den Satelliten durchgeführt. 

Zwar wird durch diesen Ansatz die Menge an Speicher pro Datenbank limitiert, jedoch sagen die Autoren des Papers \cite{SALOMIE}, das der Ansatz mehrere Datenbanken mit einem Teilspeicher schneller sei, als eine herkömmliche Datenbank, die über den gesamten Speicher verfügt.